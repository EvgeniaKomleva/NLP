{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipe-line –º–æ—Ä—Ñ–æ—Ä–∞–∑–º–µ—Ç–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "\n",
    "1 [–û—á–∏—Å—Ç–∫–∞ –∏ –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞]\n",
    "\n",
    "2 –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è\n",
    "\n",
    "3 –ú–æ—Ä—Ñ–æ–∞–Ω–∞–ª–∏–∑ (—Å–Ω—è—Ç–∏–µ –æ–º–æ–Ω–∏–º–∏–∏)\n",
    "\n",
    "4 –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è\n",
    "\n",
    "5 –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–ø–æ–∑–∏—Ç–æ–≤ (—Å–ª–æ–≤–æ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏\n",
    "—Å–ª–æ–≤–æ—Å–ª–æ–∂–µ–Ω–∏–µ)\n",
    "\n",
    "6 –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ–æ–ª–æ–≥–∏–∑–º–æ–≤ –∏ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö\n",
    "–∏–º–µ–Ω (–º–æ—Ä—Ñ–æ–∞–Ω–∞–ª–∏–∑ –∏ –ø—Å–µ–≤–¥–æ–ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è)\n",
    "\n",
    "7 –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—à–∏–±–æ–∫\n",
    "\n",
    "!!–ö–æ—Ä–ø—É—Å —Å–æ–∑–¥–∞–Ω –Ω–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –≥—Ä—É–ø–ø –≤ –í–ö!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2, re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>–º–∞–≥–Ω–∏—Ç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤ –ü–æ—Å—Ç—É–ø–∏–ª–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–ö—É—Ä—Ç –í–æ–Ω–Ω–µ–≥—É—Ç ¬´ –ö–æ–ª—ã–±–µ–ª—å –¥–ª—è –∫–æ—à–∫–∏ ¬ª –ü—Ä–æ–¥–æ–ª–∂–∞—é...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–ù–∞–¥–æ –ø–æ—É–≥–∞—Ä–∞—Ç—å –≤–∑—è—Ç—å –ø–∞–∫–µ—Ç –∏–∑ –º–∞–≥–Ω–∏—Ç–∞ –∏ –∑–∞–∫—É–ø–∏...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>üëåüèª‚òùüèªüëèüèªüëèüèªüëèüèª —à–∏—Ä–ª–∏-–º—ã—Ä–ª–∏-5.gif –ö—Ç–æ –≤—Å–µ —ç—Ç–∏ –ª—é–¥–∏ ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0                                            –º–∞–≥–Ω–∏—Ç \n",
       "1  –°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤ –ü–æ—Å—Ç—É–ø–∏–ª–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ...\n",
       "2  –ö—É—Ä—Ç –í–æ–Ω–Ω–µ–≥—É—Ç ¬´ –ö–æ–ª—ã–±–µ–ª—å –¥–ª—è –∫–æ—à–∫–∏ ¬ª –ü—Ä–æ–¥–æ–ª–∂–∞—é...\n",
       "3  –ù–∞–¥–æ –ø–æ—É–≥–∞—Ä–∞—Ç—å –≤–∑—è—Ç—å –ø–∞–∫–µ—Ç –∏–∑ –º–∞–≥–Ω–∏—Ç–∞ –∏ –∑–∞–∫—É–ø–∏...\n",
       "4  üëåüèª‚òùüèªüëèüèªüëèüèªüëèüèª —à–∏—Ä–ª–∏-–º—ã—Ä–ª–∏-5.gif –ö—Ç–æ –≤—Å–µ —ç—Ç–∏ –ª—é–¥–∏ ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('corp.csv', sep='\\t')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>23242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>23087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>–í   –±–æ–ª—å—à–æ–π –≤—ã–±–æ—Ä</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      text\n",
       "count                23242\n",
       "unique               23087\n",
       "top     –í   –±–æ–ª—å—à–æ–π –≤—ã–±–æ—Ä \n",
       "freq                     5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()#–õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'–∫–æ—Ç—ã'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('–∫–æ—Ç—ã')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()#–ú–æ—Ä—Ñ–æ–∞–Ω–∞–ª–∏–∑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parse(word='–±–µ–∂–∞–ª–∞', tag=OpencorporaTag('VERB,perf,intr femn,sing,past,indc'), normal_form='–±–µ–∂–∞—Ç—å', score=0.5, methods_stack=((<DictionaryAnalyzer>, '–±–µ–∂–∞–ª–∞', 374, 2),))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morph.parse('–±–µ–∂–∞–ª–∞')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normy_text(text):\n",
    "    new_text = ''\n",
    "    grams_exclusion = {'PREP', 'CONJ', 'INTJ', 'Name', 'Surn', 'Patr', 'Orgn', 'Trad'}\n",
    "#     grams_exclusion = {'PREP', 'CONJ', 'PRCL', 'INTJ', 'Name', 'Surn', 'Patr', 'Orgn', 'Trad'}\n",
    "    # PREP - –ø—Ä–µ–¥–ª–æ–≥.\n",
    "    # CONJ - —Å–æ—é–∑.\n",
    "    # PRCL - —á–∞—Å—Ç–∏—Ü–∞.\n",
    "    # INTJ - –º–µ–∂–¥–æ–º–µ—Ç–∏–µ.\n",
    "    # Name - –∏–º—è.\n",
    "    # Surn - –§–∞–º–∏–ª–∏—è.\n",
    "    # Patr - –æ—Ç—á–µ—Å—Ç–≤–æ.\n",
    "    # Orgn - –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è.\n",
    "    # Trad - —Ç–æ—Ä–≥–æ–≤–∞—è –º–∞—Ä–∫–∞.\n",
    "    # text = re.sub('[^–∞-—è–ê-–Øa-zA-Z]', ' ', text)\n",
    "    text = re.sub('[^–∞-—è–ê-–Øa-zA-Z—ë–Å]', ' ', text)\n",
    "    sent_tokenize(text)\n",
    "    words = text.split()\n",
    "    for word in words:\n",
    "        #k = lemmatizer.lemmatize(word)\n",
    "        p = morph.parse(word)[0]\n",
    "        if not any(tag in p.tag for tag in grams_exclusion):\n",
    "            new_text += ' ' + p.normal_form\n",
    "    new_text = new_text[1:]\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: normy_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('corp_clean.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>–º–∞–≥–Ω–∏—Ç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>—Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–¥–ø–∏—Å—á–∏–∫ –ø–æ—Å—Ç—É–ø–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –∑–∞–º–∏–Ω–∏...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–≤–æ–Ω–Ω–µ–≥—É—Ç–∞ –∫–æ–ª—ã–±–µ–ª—å –∫–æ—à–∫–∞ –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å –º–æ–π —Ä–∞—Å—Å–∫–∞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–Ω–∞–¥–æ –ø–æ—É–≥–∞—Ä–∞—Ç—å –≤–∑—è—Ç—å –ø–∞–∫–µ—Ç –º–∞–≥–Ω–∏—Ç –∑–∞–∫—É–ø–∏—Ç—å—Å—è –≤...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>—à–∏—Ä–ª–∏—Ç—å –º—ã—Ä–ª–∏ gif –∫—Ç–æ –≤–µ—Å—å —ç—Ç–æ—Ç —á–µ–ª–æ–≤–µ–∫ –∫–æ—Ç–æ—Ä—ã...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0                                             –º–∞–≥–Ω–∏—Ç\n",
       "1  —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–¥–ø–∏—Å—á–∏–∫ –ø–æ—Å—Ç—É–ø–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –∑–∞–º–∏–Ω–∏...\n",
       "2  –≤–æ–Ω–Ω–µ–≥—É—Ç–∞ –∫–æ–ª—ã–±–µ–ª—å –∫–æ—à–∫–∞ –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å –º–æ–π —Ä–∞—Å—Å–∫–∞...\n",
       "3  –Ω–∞–¥–æ –ø–æ—É–≥–∞—Ä–∞—Ç—å –≤–∑—è—Ç—å –ø–∞–∫–µ—Ç –º–∞–≥–Ω–∏—Ç –∑–∞–∫—É–ø–∏—Ç—å—Å—è –≤...\n",
       "4  —à–∏—Ä–ª–∏—Ç—å –º—ã—Ä–ª–∏ gif –∫—Ç–æ –≤–µ—Å—å —ç—Ç–æ—Ç —á–µ–ª–æ–≤–µ–∫ –∫–æ—Ç–æ—Ä—ã..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
