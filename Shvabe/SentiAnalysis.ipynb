{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "SentiAnalysis.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrrTuLW34t6w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "dataset = pd.read_csv('test.csv', delimiter=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynpCz5TE4t64",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "5f78cb16-ff98-4067-9622-bfe4c6583d43"
      },
      "source": [
        "dataset.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9386 entries, 0 to 9385\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    9386 non-null   object\n",
            " 1   label   9386 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 146.8+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pnYATOX4t6_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "5c269e4b-1776-4992-a418-29a2036f0529"
      },
      "source": [
        "dataset.label.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0    3171\n",
              "-1    3165\n",
              " 1    3050\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7w1U8co4t7F",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### TF-IDF \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m2d5ZRc4t7G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "d1f9e09a-d3b9-48b4-b7f4-3ad9ff752f83"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import metrics\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.naive_bayes import ComplementNB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "GNB = GaussianNB()\n",
        "CNB = ComplementNB()\n",
        "BNB = BernoulliNB()\n",
        "MNB = MultinomialNB()\n",
        "\n",
        "tfidf = TfidfVectorizer()\n",
        "text_count_2 = tfidf.fit_transform(dataset['text'])\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(text_count_2, dataset['label'],test_size=0.25,random_state=5)\n",
        "\n",
        "MNB.fit(x_train, y_train)\n",
        "accuracy_score_mnb = metrics.accuracy_score(MNB.predict(x_test), y_test)\n",
        "print('accuracy_score_mnb = '+str('{:4.2f}'.format(accuracy_score_mnb*100))+'%')\n",
        "\n",
        "BNB.fit(x_train, y_train)\n",
        "accuracy_score_bnb = metrics.accuracy_score(BNB.predict(x_test), y_test)\n",
        "print('accuracy_score_bnb = '+str('{:4.2f}'.format(accuracy_score_bnb*100))+'%')\n",
        "\n",
        "CNB.fit(x_train, y_train)\n",
        "accuracy_score_cnb = metrics.accuracy_score(CNB.predict(x_test), y_test)\n",
        "print('accuracy_score_cnb = '+str('{:4.2f}'.format(accuracy_score_cnb*100))+'%')\n",
        "\n",
        "GNB.fit(x_train.todense(), y_train)\n",
        "accuracy_score_gnb = metrics.accuracy_score(GNB.predict(x_test.todense()), y_test)\n",
        "print('accuracy_score_gnb = '+str('{:4.2f}'.format(accuracy_score_gnb*100))+'%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy_score_mnb = 65.10%\n",
            "accuracy_score_bnb = 61.48%\n",
            "accuracy_score_cnb = 64.64%\n",
            "accuracy_score_gnb = 51.17%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70Nfhppm4t7L",
        "colab_type": "text"
      },
      "source": [
        "### Попробуем выбрать классификатор стохастического градиентного спуска или SVM. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iro-q9Vo4t7M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "16bc184f-e4bd-409f-cd4f-2dce76b2d094"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
        "\n",
        "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
        "\n",
        "SGDC = SGDClassifier()\n",
        "LSVC = LinearSVC()\n",
        "cv = CountVectorizer(stop_words=stopwords.words('russian'), ngram_range = (2,2), tokenizer = token.tokenize)\n",
        "\n",
        "text_counts = cv.fit_transform(dataset['text'])\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(text_counts, dataset['label'],test_size=0.25, random_state=5)\n",
        "\n",
        "#on TF-IDF data\n",
        "LSVC.fit(x_train, y_train)\n",
        "accuracy_score_lsvc = metrics.accuracy_score(LSVC.predict(x_test), y_test)\n",
        "print('accuracy_score_lsvc = '+str('{:4.2f}'.format(accuracy_score_lsvc*100))+'%')\n",
        "\n",
        "SGDC.fit(x_train, y_train)\n",
        "accuracy_score_sgdc = metrics.accuracy_score(SGDC.predict(x_test), y_test)\n",
        "print('accuracy_score_sgdc = '+str('{:4.2f}'.format(accuracy_score_sgdc*100))+'%')\n",
        "\n",
        "#on CountVectorize data\n",
        "LSVC.fit(X_train, Y_train)\n",
        "accuracy_score_lsvc_CV = metrics.accuracy_score(LSVC.predict(X_test), Y_test)\n",
        "print('accuracy_score_lsvc_cv = '+str('{:4.2f}'.format(accuracy_score_lsvc_CV*100))+'%')\n",
        "\n",
        "SGDC.fit(X_train, Y_train)\n",
        "accuracy_score_sgdc_CV = metrics.accuracy_score(SGDC.predict(X_test), Y_test)\n",
        "print('accuracy_score_sgdc_cv = '+str('{:4.2f}'.format(accuracy_score_sgdc_CV*100))+'%')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy_score_lsvc = 66.64%\n",
            "accuracy_score_sgdc = 67.02%\n",
            "accuracy_score_lsvc_cv = 41.41%\n",
            "accuracy_score_sgdc_cv = 41.41%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}